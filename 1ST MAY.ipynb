{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "437483dc-cc0f-48f3-b249-5bd3104c532f",
   "metadata": {},
   "source": [
    "# Q1. Contingency Matrix in Classification Evaluation:\n",
    "\n",
    "A contingency matrix (also known as a confusion matrix) is a table used in classification to assess the performance of a model.\n",
    "It compares the predicted class labels to the true class labels, breaking down the counts into categories such as true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "# Q2. Pair Confusion Matrix:\n",
    "\n",
    "A pair confusion matrix extends the idea of a regular confusion matrix to evaluate the performance of models in binary or pairwise classification.\n",
    "It is useful when dealing with imbalanced datasets, providing a detailed breakdown of the performance on each pair of classes.\n",
    "\n",
    "# Q3. Extrinsic Measure in NLP:\n",
    "\n",
    "An extrinsic measure evaluates the performance of a language model in the context of a specific application or task.\n",
    "For example, in natural language processing, precision, recall, and F1-score may be used to evaluate a model's performance on tasks like sentiment analysis or named entity recognition.\n",
    "Q4. Intrinsic Measure in Machine Learning:\n",
    "\n",
    "An intrinsic measure evaluates a model's performance based on its internal characteristics, without considering its performance on a specific task.\n",
    "In machine learning, this could involve assessing the quality of a representation learned by an unsupervised algorithm.\n",
    "\n",
    "# Q5. Confusion Matrix Purpose:\n",
    "\n",
    "A confusion matrix provides a comprehensive view of a classification model's performance.\n",
    "It helps identify:\n",
    "True Positives (correctly predicted positives).\n",
    "True Negatives (correctly predicted negatives).\n",
    "False Positives (actual negatives but predicted as positives).\n",
    "False Negatives (actual positives but predicted as negatives).\n",
    "From these, various metrics like accuracy, precision, recall, and F1-score can be calculated.\n",
    "\n",
    "# Q6. Intrinsic Measures for Unsupervised Learning:\n",
    "\n",
    "For unsupervised learning, intrinsic measures include:\n",
    "Silhouette Score: Measures how well-separated clusters are.\n",
    "Davies-Bouldin Index: Evaluates the compactness and separation of clusters.\n",
    "Calinski-Harabasz Index: Quantifies the ratio of between-cluster variance to within-cluster variance.\n",
    "Interpretation depends on the specific measure; higher values generally indicate better performance.\n",
    "\n",
    "# Q7. Limitations of Accuracy as Sole Metric:\n",
    "\n",
    "Imbalanced Datasets: Accuracy may be high even if the model is biased towards the majority class.\n",
    "Misleading in Some Contexts: In tasks with severe consequences for certain errors (e.g., medical diagnoses), accuracy alone might not be sufficient.\n",
    "Doesn't Account for Type I and Type II Errors: Precision and recall provide additional insights into a model's strengths and weaknesses.\n",
    "Threshold Sensitivity: The choice of the classification threshold can impact accuracy; other metrics can be threshold-independent.\n",
    "Feel free to ask if you have any further questions or need more clarification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109db62-2c1d-443b-ac84-a287722fb0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
